# Visual Grounding with Vision-Language Model
This implementation provides a vision-language model for visual grounding tasks, where the model predicts bounding box coordinates for objects described in natural language.
- Motivations
  - [IDK Token, NeurIPS 2024](https://arxiv.org/pdf/2412.06676)
  - [NextChat, ICML 2024](https://next-chatv.github.io/)

# Note
- This repository is not fully implemented and is not ready to use.
  - 아직 완전히 구현 되지 않았습니다 !

# Usage
## Installation
- ...
## Training
- 학습은 크게 2 단계로 나뉨
  - Stage 1 : Training Visual Grounding Model (Multi-Task)
  - Stage 2 : IDK Token Post Training
## Data Preprocessing
- ...

# To do
- 데이터셋, 로더 파트 구현 필요
  - Conversation form ?
